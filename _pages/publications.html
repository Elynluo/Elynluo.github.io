---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
<div class="wordwrap">You can also find my articles on <a href="https://scholar.google.com/citations?user=YGzd7BMAAAAJ">my Google Scholar profile</a>.</div>

<html>
<head>

<style>
  div.pub {
    line-height: 120%;
  }

  .publication {
    display: grid; /* Use grid display for layout */
    grid-template-columns: 150px 1fr; /* Two columns: 150px for image, 1fr for text */
    align-items: flex-start; /* Align items to the top */
    gap: 10px; /* Add some gap between image and text */
    margin-bottom: 45px;
  }

  .publication-image {
    margin-right: 10px;
    width: 150px; /* Set a fixed width for the image container */
    height: 150px; /* Set a fixed height for the image container */
    overflow: hidden; /* Hide any overflowing content within the container, original hidden */
  }

  .publication-image img {
    width: 100%; /* Ensure the image fills the container horizontally */
    height: 100%; /* Ensure the image fills the container vertically */
    object-fit: scale-down; /* Maintain aspect ratio and crop if necessary, original cover */
  }

  .publication-details {
    display: inline-block;
    vertical-align: top;
    flex-grow: 1; /* Expand to fill available space */
  }
</style>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4XRR1S1L4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4XRR1S1L4');
</script>
<body>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2025</h2>
<!-- pub 19 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/breast_2025.png" alt="breast_2025" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://www.nature.com/articles/s41551-025-01435-3" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            18. Panoramic photoacoustic computed tomography with learning-based classification enhances breast lesion characterization
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Xin Tong*, Cindy Z. Liu*, <span style="color: #213555;"><strong>Yilin Luo*</strong></span>, Li Lin], Jessica Dzubnar, Marta Invernizzi, Stephanie Delos Santos, Yide Zhang, Rui Cao, Peng Hu, Junfu Zheng, Jaclene Torres, Armine Kasabyan, Lily L. Lai, Lisa D. Yee, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Nature Biomedical Engineering (2025) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We introduce a workflow using panoramic PACT for breast lesion characterization, offering detailed visualization of vasculature irrespective of breast density. 
      </span>
    </font>
  </div>
</div>

<!-- pub 18 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/RUS-PAT_2025.png" alt="RUS-PAT_2025" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://arxiv.org/abs/2504.16036" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            18. Rotational ultrasound and photoacoustic tomography of the human body
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Yang Zhang*, Shuai Na*, Jonathan J. Russin*], Karteekeya Sastry, Li Lin, Junfu Zheng, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Xin Tong, Yujin An, Peng Hu, Konstantin Maslov, Tze-Woei Tan, Charles Y. Liu, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Arkiv (2025) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present integrate fast panoramic rotational ultrasound tomography (RUST) and PAT for hybrid rotational ultrasound and photoacoustic tomography (RUS-PAT), which obtains 3D ultrasound structural and PAT angiographic images of the human body quasi-simultaneously. 
      </span>
    </font>
  </div>
</div>

<!-- pub 17 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/CVD_2025.jpg" alt="CVD_2025" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1007/s11936-025-01092-4" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            17. Photoacoustic tomography in cardiovascular medicine: innovations in assessing hemodynamics and metabolic function
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Current Treatment Options Cardiovascular Medicine 27(35) (2025) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        This review highlights recent advancements in photoacoustic tomography for assessing hemodynamics and metabolic function in the diagnosis, treatment, and monitoring of cardiovascular diseases.
      </span>
    </font>
  </div>
</div>

<!-- pub 16 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/BEM_2025.png" alt="BEM_2025" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://ieeexplore.ieee.org/abstract/document/10829500" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            16. Transcranial photoacoustic tomography de-aberrated using boundary elements
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Karteekeya Sastry*, Yousuf Aborahama*], <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yang Zhang, Manxiu Cui, Rui Cao, Geng Ku, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> IEEE Transcations on Medical Imaging, 44(5), pp. 2068-2078 (2025) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We develop an acoustic solver based on the boundary-element method (BEM) to model the skull and de-aberrate the images. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2024</h2>

<!-- pub 15 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/PUV-PAM_2024.jpg" alt="PUV-PAM_2024" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://www.science.org/doi/10.1126/sciadv.ado0518" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            15. Optical-resolution parallel ultraviolet photoacoustic microscopy for slide-free histology
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Rui Cao, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Jingjing Zhao, Yide Zhang, Qifa Zhou, Adam Le Da Zerda, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Science Advances, 10(50), eado0518 (2024) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present parallel ultraviolet photoacoustic microscopy (PUV-PAM) with simultaneous scanning of eight optical foci to acquire histology-like images of slide-free fresh specimens, improving the ultraviolet PAM imaging speed limited by low laser repetition rates. 
      </span>
    </font>
  </div>
</div>

<!-- pub 14 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/FEM_2024.png" alt="FEM_2024" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1109/TMI.2024.3456595" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            14. Full-wave image reconstruction in transcranial photoacoustic computed tomography using a finite element method 
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Hsuan-Kai Huang, Karteekeya Sastry, Peng Hu, Xin Tong, Joseph Kuo, Yousuf Aborahama, Shuai Na, Umberto Villa, Mark. A. Anastasio, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> IEEE Transcations on Medical Imaging, 44(2), pp. 645-655 (2024) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We propose an efficient discrete imaging model based on finite element discretization to facilitate accurate whole-brain simulations with improved speed. 
      </span>
    </font>
  </div>
</div>

<!-- pub 13 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/Kwave_2024.png" alt="Kwave_2024" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://arxiv.org/pdf/2404.05937" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            13. De-aberration for transcranial photoacoustic computed tomography through an adult human skull
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Yousuf Aborahama*, Karteekeya Sastry*, Manxiu Cui*], Yang Zhang, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Rui Cao, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Arkiv (2024) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We report the first successful experimental demonstration of the de-aberration of PACT images through an ex-vivo adult human skull using a homogeneous elastic model for the skull. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2023</h2>
<!-- pub 12 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/calibration_2023.png" alt="calibration_2023" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1016/j.pacs.2023.100520" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            12. A method for the geometric calibration of ultrasound transducer arrays with arbitrary geometries
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Karteekeya Sastry, Yang Zhang, Peng Hu, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Xin Tong, Shuai Na, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Photoacoustics, 32, 100520 (2023) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present a geometric calibration method that is applicable to a wide range of PACT systems. 
      </span>
    </font>
  </div>
</div>

<!-- pub 11 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/3KPACT_2023.png" alt="3KPACT_2023" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10327245/" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            11. Single-shot 3D photoacoustic computed tomography with a densely packed array for transcranial functional imaging
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Rui Cao*, <span style="color: #213555;"><strong>Yilin Luo*</strong></span>], Jinhua Xu, Xiaofei Luo, Ku Geng, Yousuf Aborahama, Manxiu Cui, Samuel Davis, Shuai Na, Xin Tong, Cindy Liu, Karteek Sastry, Konstatin Maslov, Peng Hu, Yide Zhang, Li Lin, Yang Zhang, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> ArXiv (2023) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We have engineered a state-of-the-art PACT system that features a densely packed hemispherical ultrasonic transducer array for human transcranial imaging.
      </span>
    </font>
  </div>
</div>

<!-- pub 10 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/bone_2023.png" alt="bone_2023" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41551-022-00940-z" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            10. Label-free intraoperative histology of bone tissue via deep-learning-assisted ultraviolet photoacoustic microscopy
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Rui Cao, Scott D. Nelson, Samuel Davis, Yu Liang, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yide Zhang, Brooke Crawford, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Nature biomedical engineering, 7(2), 124-134 (2023) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We show that real-time three-dimensional contour-scanning of tissue via ultraviolet photoacoustic microscopy in reflection mode can be used to intraoperatively evaluate undecalcified and decalcified thick bone specimens, without the need for tissue sectioning. 
      </span>
    </font>
  </div>
</div>

<!-- pub 9 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/needleBeam_2023.png" alt="needleBeam_2023" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41566-022-01112-w" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            9. Optical-resolution photoacoustic microscopy with a needle-shaped beam
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Rui Cao, Jingjing Zhao, Lei Li, Lin Du, Yide Zhang, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Laiming Jiang, Samuel Davis, Qifa Zhou, Adam de la Zerda, Lihong V. Wang
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Nature photonics, 17(1), 89-95 (2023) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We propose needle-shaped beam photoacoustic microscopy, which can extend the depth of field to around a 28-fold Rayleigh length via customized diffractive optical elements. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2021</h2>

<!-- pub 8 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/OCT_2021.png" alt="OCT_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-021-00594-7" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            8. Neural network-based image reconstruction in swept-source optical coherence tomography using undersampled spectral data
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Yijie Zhang*, Tairan Liu*], Manmohan Singh, Ege Çetintaş, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yair Rivenson, Kirill V. Larin, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 10(1), 155 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present a deep learning-based image reconstruction framework that can generate swept-source OCT (SS-OCT) images using undersampled spectral data, without any spatial aliasing artifacts. 
      </span>
    </font>
  </div>
</div>

<!-- pub 7 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/RNN_2021.png" alt="RNN_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-021-00506-9" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            7. Recurrent neural network-based volumetric fluorescence microscopy
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Luzhe Huang, Hanlong Chen, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yair Rivenson, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 10(1), 62 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We report a deep learning-based volumetric image inference framework that uses 2D images that are sparsely captured by a standard wide-field fluorescence microscope at arbitrary axial positions within the sample volume. 
      </span>
    </font>
  </div>
</div>


<!-- pub 6 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/doubleHelix_2021.png" alt="doubleHelix_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://pubs.acs.org/doi/10.1021/acsphotonics.1c00660" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            6. Deep-Learning-based virtual refocusing of images using an engineered point-spread function
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Xilin Yang*, Luzhe Huang]*, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yichen Wu, Hongda Wang, Yair Rivenson, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> ACS Photonics, 8(7), 2174-2182 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present a virtual refocusing method over an extended depth of field (DOF) enabled by cascaded neural networks and a double-helix point-spread function (DH-PSF). 
      </span>
    </font>
  </div>
</div>

<!-- pub 5 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/deepR_2021.png" alt="deepR_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://pubs.acs.org/doi/10.1021/acsphotonics.0c01774" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            5. Single-shot autofocusing of microscopy images using deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [<span style="color: #213555;"><strong>Yilin Luo*</strong></span>, Luzhe Huang*], Yair Rivenson, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> ACS Photonics, 8(2), 625-638 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We demonstrate a deep learning-based offline autofocusing method, termed Deep-R, that is trained to rapidly and blindly autofocus a single-shot microscopy image of a specimen that is acquired at an arbitrary out-of-focus plane. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2019</h2>
<!-- pub 4 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/deepZ_2019.png" alt="deepZ_2019" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41592-019-0622-5" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            4. Three-dimensional virtual refocusing of fluorescence microscopy images using deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Yichen Wu*, Yair Rivenson*], Hongda Wang, <span style="color: #213555;"><strong>Yilin Luo*</strong></span>, Eyal Ben-David, Laurent A. Bentolila, Christian Pritz, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Nature methods, 16(12), 1323-1331 (2019) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We show a deep neural network can be trained to virtually refocus a two-dimensional fluorescence image onto user-defined three-dimensional (3D) surfaces within the sample. 
      </span>
    </font>
  </div>
</div>

<!-- pub 3 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/brightfield_2019.png" alt="brightfield_2019" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-019-0139-9" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            3. Bright-field holography: cross-modality deep learning enables snapshot 3D imaging with bright-field contrast using a single hologram
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [Yichen Wu*, <span style="color: #213555;"><strong>Yilin Luo*</strong></span>], Gunvant Chaudhari, Yair Rivenson, Ayfer Calis, Kevin De Haan, Aydogan Ozcan.
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 8(1), 25 (2019) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We demonstrate that cross-modality deep learning using a generative adversarial network (GAN) can endow holographic images of a sample volume with bright-field microscopy contrast, combining the volumetric imaging capability of holography with the speckle- and artifact-free image contrast of incoherent bright-field microscopy. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2018</h2>
<!-- pub 2 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/motility_2018.png" alt="motility_2018" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-018-0110-1" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            2. Motility-based label-free detection of parasites in bodily fluids using holographic speckle analysis and deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Yibo Zhang, Hatice Ceylan Koydemir, Michelle M Shimogawa, Sener Yalcin, Alexander Guziak, Tairan Liu, Ilker Oguz, Yujia Huang, Bijie Bai, <span style="color: #213555;"><strong>Yilin Luo</strong></span>, Yi Luo, Zhensong Wei, Hongda Wang, Vittorio Bianco, Bohan Zhang, Rohan Nadkarni, Kent Hill, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 7(1), 108 (2018) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        A motility-based label-free computational imaging platform is developed to rapidly detect motile parasites in optically dense bodily fluids by utilizing the locomotion of the parasites as a specific biomarker and endogenous contrast mechanism.
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2017</h2>
<!-- pub 1 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/senilePlaque_2017.png" alt="senilePlaque_2017" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1364/OL.42.004247" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            1. Label-free brainwide visualization of senile plaque using cryo-micro-optical sectioning tomography
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        [<span style="color: #213555;"><strong>Yilin Luo*</strong></span>, Anle Wang*], Mengmeng Liu, Tian Lei, Xiaochuan Zhang, Zhaobing Gao, Hualiang Jiang, Hui Gong, Jing Yuan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Optics Letters, 42(21), 4247-4250 (2017) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We develop cryo-micro-optical sectioning tomography (cryo-MOST) to capture intrinsic fluorescence distribution of senile plaques at a micrometer-level resolution in the whole brain.
      </span>
    </font>
  </div>
</div>


<font size="2">
  <br>
  <span style="color: gray;">
    Updated on June, 2025
  </span>
</font>


