---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---
<div class="wordwrap">You can also find my articles on <a href="https://scholar.google.com/citations?user=YGzd7BMAAAAJ">my Google Scholar profile</a>.</div>

<html>
<head>
<style>
  div.pub {
    line-height: 120%;
  }

  .publication {
    display: grid; /* Use grid display for layout */
    grid-template-columns: 150px 1fr; /* Two columns: 150px for image, 1fr for text */
    align-items: flex-start; /* Align items to the top */
    gap: 10px; /* Add some gap between image and text */
    margin-bottom: 45px;
  }

  .publication-image {
    margin-right: 10px;
    width: 150px; /* Set a fixed width for the image container */
    height: 150px; /* Set a fixed height for the image container */
    overflow: hidden; /* Hide any overflowing content within the container, original hidden */
  }

  .publication-image img {
    width: 100%; /* Ensure the image fills the container horizontally */
    height: 100%; /* Ensure the image fills the container vertically */
    object-fit: scale-down; /* Maintain aspect ratio and crop if necessary, original cover */
  }

  .publication-details {
    display: inline-block;
    vertical-align: top;
    flex-grow: 1; /* Expand to fill available space */
  }
</style>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-J4XRR1S1L4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-J4XRR1S1L4');
</script>
<body>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2021</h2>
<!-- pub 6 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/OCT_2021.png" alt="OCT_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-021-00594-7" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            6. Neural network-based image reconstruction in swept-source optical coherence tomography using undersampled spectral data
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Yijie Zhang, Tairan Liu, Manmohan Singh, Ege Çetintaş, <span style="color: #213555;"><strong>Yilin Luo,</strong></span> Yair Rivenson, Kirill V. Larin, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 10(1), p155 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We present a deep learning-based image reconstruction framework that can generate swept-source OCT (SS-OCT) images using undersampled spectral data, without any spatial aliasing artifacts. 
      </span>
    </font>
  </div>
</div>

<!-- pub 5 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/deepR_2021.png" alt="deepR_2021" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://pubs.acs.org/doi/10.1021/acsphotonics.0c01774" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            5. Single-shot autofocusing of microscopy images using deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        <span style="color: #213555;"><strong>Yilin Luo*,</strong></span> Luzhe Huang, Yair Rivenson, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> ACS Photonics, 8(2), 625-638 (2021) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We demonstrate a deep learning-based offline autofocusing method, termed Deep-R, that is trained to rapidly and blindly autofocus a single-shot microscopy image of a specimen that is acquired at an arbitrary out-of-focus plane. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2019</h2>
<!-- pub 4 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/deepZ_2019.png" alt="deepZ_2019" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41592-019-0622-5" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            4. Three-dimensional virtual refocusing of fluorescence microscopy images using deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Yichen Wu, Yair Rivenson, Hongda Wang, <span style="color: #213555;"><strong>Yilin Luo*,</strong></span> Eyal Ben-David, Laurent A. Bentolila, Christian Pritz, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Nature methods, 16(12), 1323-1331 (2019) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We show a deep neural network can be trained to virtually refocus a two-dimensional fluorescence image onto user-defined three-dimensional (3D) surfaces within the sample. 
      </span>
    </font>
  </div>
</div>

<!-- pub 3 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/brightfield_2019.png" alt="brightfield_2019" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-019-0139-9" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            3. Bright-field holography: cross-modality deep learning enables snapshot 3D imaging with bright-field contrast using a single hologram
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Wu, Yichen*, <span style="color: #213555;"><strong>Yilin Luo*,</strong></span> Gunvant Chaudhari, Yair Rivenson, Ayfer Calis, Kevin De Haan, Aydogan Ozcan.
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 8(1), 25 (2019) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We demonstrate that cross-modality deep learning using a generative adversarial network (GAN) can endow holographic images of a sample volume with bright-field microscopy contrast, combining the volumetric imaging capability of holography with the speckle- and artifact-free image contrast of incoherent bright-field microscopy. 
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2018</h2>
<!-- pub 2 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/motility_2018.png" alt="motility_2018" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1038/s41377-018-0110-1" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            2. Motility-based label-free detection of parasites in bodily fluids using holographic speckle analysis and deep learning
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        Yibo Zhang, Hatice Ceylan Koydemir, Michelle M Shimogawa, Sener Yalcin, Alexander Guziak, Tairan Liu, Ilker Oguz, Yujia Huang, Bijie Bai, <span style="color: #213555;"><strong>Yilin Luo,</strong></span> Yi Luo, Zhensong Wei, Hongda Wang, Vittorio Bianco, Bohan Zhang, Rohan Nadkarni, Kent Hill, Aydogan Ozcan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Light: Science & Applications, 7(1), 108 (2018) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        A motility-based label-free computational imaging platform is developed to rapidly detect motile parasites in optically dense bodily fluids by utilizing the locomotion of the parasites as a specific biomarker and endogenous contrast mechanism.
      </span>
    </font>
  </div>
</div>

<h2 id="{{ year | slugify }}" class="archive__subtitle">2017</h2>
<!-- pub 1 -->
<div class="publication">
  <div class="publication-image">
    <img src="https://raw.githubusercontent.com/elynluo/elynluo.github.io/master/_publications/senilePlaque_2017.png" alt="senilePlaque_2017" width="150" height="150">
  </div>
  <div class="publication-details">
    <font size="4">
      <a href="https://doi.org/10.1364/OL.42.004247" style="text-decoration: none;">
        <span style="color: #191717;">
          <strong>
            1. Label-free brainwide visualization of senile plaque using cryo-micro-optical sectioning tomography
          </strong>
        </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: #A4907C;">
        <span style="color: #213555;"><strong>Yilin Luo*,</strong></span> Anle Wang*, Mengmeng Liu, Tian Lei, Xiaochuan Zhang, Zhaobing Gao, Hualiang Jiang, Hui Gong, Jing Yuan
      </span>
    </font>
    <br>
    <font size="3" style="font-family: 'Font', Calibri;">
      <a style="text-decoration: none;">
        <span style="color: #B2533E;"> Optics Letters, 42(21), 4247-4250 (2017) </span>
      </a>
    </font>
    <br>
    <font size="3">
      <span style="color: gray;">
        We develop cryo-micro-optical sectioning tomography (cryo-MOST) to capture intrinsic fluorescence distribution of senile plaques at a micrometer-level resolution in the whole brain.
      </span>
    </font>
  </div>
</div>


<font size="2">
  <br>
  <span style="color: gray;">
    Updated on Sept. 5, 2024
  </span>
</font>


